{
  "nodes": [
    {
      "id": "customTool_0",
      "position": {
        "x": 644.853148172387,
        "y": -504.7450245751089
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_0-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_0-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "57f19e61-b99a-4179-9317-bf547e99e9a8",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 374,
      "selected": false,
      "positionAbsolute": {
        "x": 644.853148172387,
        "y": -504.7450245751089
      },
      "dragging": false
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": 841.1504838316146,
        "y": 371.6375313987337
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 254,
      "selected": false,
      "positionAbsolute": {
        "x": 841.1504838316146,
        "y": 371.6375313987337
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 839.3691522917226,
        "y": 658.533415019343
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 2.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-pro",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses vision model when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, Conversational Agent, Tool Agent",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-1.5-flash-latest",
          "customModelName": "",
          "temperature": "0.4",
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 672,
      "selected": false,
      "positionAbsolute": {
        "x": 839.3691522917226,
        "y": 658.533415019343
      },
      "dragging": false
    },
    {
      "id": "requestsGet_0",
      "position": {
        "x": 977.3239476281569,
        "y": -436.4907003868004
      },
      "type": "customNode",
      "data": {
        "id": "requestsGet_0",
        "label": "Requests Get",
        "version": 1,
        "name": "requestsGet",
        "type": "RequestsGet",
        "baseClasses": [
          "RequestsGet",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Execute HTTP GET requests",
        "inputParams": [
          {
            "label": "URL",
            "name": "url",
            "type": "string",
            "description": "Agent will make call to this exact URL. If not specified, agent will try to figure out itself from AIPlugin if provided",
            "additionalParams": true,
            "optional": true,
            "id": "requestsGet_0-input-url-string"
          },
          {
            "label": "Description",
            "name": "description",
            "type": "string",
            "rows": 4,
            "default": "A portal to the internet. Use this when you need to get specific content from a website. \nInput should be a  url (i.e. https://www.google.com). The output will be the text response of the GET request.",
            "description": "Acts like a prompt to tell agent when it should use this tool",
            "additionalParams": true,
            "optional": true,
            "id": "requestsGet_0-input-description-string"
          },
          {
            "label": "Headers",
            "name": "headers",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "requestsGet_0-input-headers-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "url": "",
          "description": "A portal to the internet. Use this when you need to get specific content from a website. \nInput should be a  url (i.e. https://www.google.com). The output will be the text response of the GET request.",
          "headers": ""
        },
        "outputAnchors": [
          {
            "id": "requestsGet_0-output-requestsGet-RequestsGet|Tool|StructuredTool|Runnable",
            "name": "requestsGet",
            "label": "RequestsGet",
            "description": "Execute HTTP GET requests",
            "type": "RequestsGet | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 254,
      "selected": false,
      "positionAbsolute": {
        "x": 977.3239476281569,
        "y": -436.4907003868004
      },
      "dragging": false
    },
    {
      "id": "toolAgent_0",
      "position": {
        "x": 1438.6138795318377,
        "y": -7.224377140349844
      },
      "type": "customNode",
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{requestsGet_0.data.instance}}",
            "{{customTool_0.data.instance}}",
            "{{chainTool_0.data.instance}}",
            "{{customTool_1.data.instance}}"
          ],
          "memory": "{{bufferMemory_0.data.instance}}",
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "chatPromptTemplate": "",
          "systemMessage": "You are a helpful AI assistant that answers only questions related to the weather of a country, a state or a city. When the name of the state or city given by the user may refer to more than one state in the world, you must ask to which one he or she refers to.",
          "inputModeration": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 488,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1438.6138795318377,
        "y": -7.224377140349844
      }
    },
    {
      "id": "chainTool_0",
      "position": {
        "x": 307.0355162715189,
        "y": -601.7915084480559
      },
      "type": "customNode",
      "data": {
        "id": "chainTool_0",
        "label": "Chain Tool",
        "version": 1,
        "name": "chainTool",
        "type": "ChainTool",
        "baseClasses": [
          "ChainTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a chain as allowed tool for agent",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "name",
            "type": "string",
            "placeholder": "state-of-union-qa",
            "id": "chainTool_0-input-name-string"
          },
          {
            "label": "Chain Description",
            "name": "description",
            "type": "string",
            "rows": 3,
            "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
            "id": "chainTool_0-input-description-string"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "type": "boolean",
            "optional": true,
            "id": "chainTool_0-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Base Chain",
            "name": "baseChain",
            "type": "BaseChain",
            "id": "chainTool_0-input-baseChain-BaseChain"
          }
        ],
        "inputs": {
          "name": "boulder_weather_information",
          "description": "useful to get historical weather information only about Boulder, Colorado from September 3rd, 2023 to August 26th, 2024.",
          "returnDirect": "",
          "baseChain": "{{retrievalQAChain_0.data.instance}}"
        },
        "outputAnchors": [
          {
            "id": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "chainTool",
            "label": "ChainTool",
            "description": "Use a chain as allowed tool for agent",
            "type": "ChainTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 604,
      "selected": false,
      "positionAbsolute": {
        "x": 307.0355162715189,
        "y": -601.7915084480559
      },
      "dragging": false
    },
    {
      "id": "retrievalQAChain_0",
      "position": {
        "x": -55.30413322731707,
        "y": -456.5790534962323
      },
      "type": "customNode",
      "data": {
        "id": "retrievalQAChain_0",
        "label": "Retrieval QA Chain",
        "version": 2,
        "name": "retrievalQAChain",
        "type": "RetrievalQAChain",
        "baseClasses": [
          "RetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "QA chain to answer a question based on the retrieved documents",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "retrievalQAChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "retrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{huggingFaceInference_LLMs_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|Runnable",
            "name": "retrievalQAChain",
            "label": "RetrievalQAChain",
            "description": "QA chain to answer a question based on the retrieved documents",
            "type": "RetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 333,
      "selected": false,
      "positionAbsolute": {
        "x": -55.30413322731707,
        "y": -456.5790534962323
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": -421.79271001049085,
        "y": -365.02605808851104
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{csvFile_0.data.instance}}"
          ],
          "embeddings": "{{googleGenerativeAiEmbeddings_0.data.instance}}",
          "topK": "31"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 408,
      "selected": false,
      "positionAbsolute": {
        "x": -421.79271001049085,
        "y": -365.02605808851104
      },
      "dragging": false
    },
    {
      "id": "googleGenerativeAiEmbeddings_0",
      "position": {
        "x": -782.3768068207895,
        "y": -255.77097293428187
      },
      "type": "customNode",
      "data": {
        "id": "googleGenerativeAiEmbeddings_0",
        "label": "GoogleGenerativeAI Embeddings",
        "version": 2,
        "name": "googleGenerativeAiEmbeddings",
        "type": "GoogleGenerativeAiEmbeddings",
        "baseClasses": [
          "GoogleGenerativeAiEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Google Generative API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "googleGenerativeAiEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "embedding-001",
            "id": "googleGenerativeAiEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Task Type",
            "name": "tasktype",
            "type": "options",
            "description": "Type of task for which the embedding will be used",
            "options": [
              {
                "label": "TASK_TYPE_UNSPECIFIED",
                "name": "TASK_TYPE_UNSPECIFIED"
              },
              {
                "label": "RETRIEVAL_QUERY",
                "name": "RETRIEVAL_QUERY"
              },
              {
                "label": "RETRIEVAL_DOCUMENT",
                "name": "RETRIEVAL_DOCUMENT"
              },
              {
                "label": "SEMANTIC_SIMILARITY",
                "name": "SEMANTIC_SIMILARITY"
              },
              {
                "label": "CLASSIFICATION",
                "name": "CLASSIFICATION"
              },
              {
                "label": "CLUSTERING",
                "name": "CLUSTERING"
              }
            ],
            "default": "TASK_TYPE_UNSPECIFIED",
            "id": "googleGenerativeAiEmbeddings_0-input-tasktype-options"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "embedding-001",
          "tasktype": "RETRIEVAL_QUERY"
        },
        "outputAnchors": [
          {
            "id": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
            "name": "googleGenerativeAiEmbeddings",
            "label": "GoogleGenerativeAiEmbeddings",
            "description": "Google Generative API to generate embeddings for a given text",
            "type": "GoogleGenerativeAiEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 469,
      "selected": false,
      "positionAbsolute": {
        "x": -782.3768068207895,
        "y": -255.77097293428187
      },
      "dragging": false
    },
    {
      "id": "csvFile_0",
      "position": {
        "x": -782.1618328372373,
        "y": -845.6949805559161
      },
      "type": "customNode",
      "data": {
        "id": "csvFile_0",
        "label": "Csv File",
        "version": 2,
        "name": "csvFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from CSV files",
        "inputParams": [
          {
            "label": "Csv File",
            "name": "csvFile",
            "type": "file",
            "fileType": ".csv",
            "id": "csvFile_0-input-csvFile-file"
          },
          {
            "label": "Single Column Extraction",
            "name": "columnName",
            "type": "string",
            "description": "Extracting a single column",
            "placeholder": "Enter column name",
            "optional": true,
            "id": "csvFile_0-input-columnName-string"
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "csvFile_0-input-metadata-json"
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "csvFile_0-input-omitMetadataKeys-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "csvFile_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "{{characterTextSplitter_0.data.instance}}",
          "columnName": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "csvFile_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "csvFile_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 541,
      "selected": false,
      "positionAbsolute": {
        "x": -782.1618328372373,
        "y": -845.6949805559161
      },
      "dragging": false
    },
    {
      "id": "characterTextSplitter_0",
      "position": {
        "x": -1145.781518812038,
        "y": -796.8662775988383
      },
      "type": "customNode",
      "data": {
        "id": "characterTextSplitter_0",
        "label": "Character Text Splitter",
        "version": 1,
        "name": "characterTextSplitter",
        "type": "CharacterTextSplitter",
        "baseClasses": [
          "CharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "splits only on one type of character (defaults to \"\\n\\n\").",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "description": "Number of characters in each chunk. Default is 1000.",
            "default": 1000,
            "optional": true,
            "id": "characterTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "description": "Number of characters to overlap between chunks. Default is 200.",
            "default": 200,
            "optional": true,
            "id": "characterTextSplitter_0-input-chunkOverlap-number"
          },
          {
            "label": "Custom Separator",
            "name": "separator",
            "type": "string",
            "placeholder": "\" \"",
            "description": "Separator to determine when to split the text, will override the default separator",
            "optional": true,
            "id": "characterTextSplitter_0-input-separator-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": 200,
          "separator": "/n"
        },
        "outputAnchors": [
          {
            "id": "characterTextSplitter_0-output-characterTextSplitter-CharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "characterTextSplitter",
            "label": "CharacterTextSplitter",
            "description": "splits only on one type of character (defaults to \"\\n\\n\").",
            "type": "CharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 478,
      "selected": false,
      "positionAbsolute": {
        "x": -1145.781518812038,
        "y": -796.8662775988383
      },
      "dragging": false
    },
    {
      "id": "huggingFaceInference_LLMs_0",
      "position": {
        "x": -421.71478613784376,
        "y": -983.5796043158841
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInference_LLMs_0",
        "label": "HuggingFace Inference",
        "version": 2,
        "name": "huggingFaceInference_LLMs",
        "type": "HuggingFaceInference",
        "baseClasses": [
          "HuggingFaceInference",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around HuggingFace large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInference_LLMs_0-input-credential-credential"
          },
          {
            "label": "Model",
            "name": "model",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "gpt2",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-model-string"
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/gpt2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-endpoint-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "description": "Top Probability parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-topP-number"
          },
          {
            "label": "Top K",
            "name": "hfTopK",
            "type": "number",
            "step": 0.1,
            "description": "Top K parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-hfTopK-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "id": "huggingFaceInference_LLMs_0-input-frequencyPenalty-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "huggingFaceInference_LLMs_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "{{inMemoryCache_0.data.instance}}",
          "model": "google/gemma-2b-it",
          "endpoint": "",
          "temperature": "",
          "maxTokens": "",
          "topP": "",
          "hfTopK": "",
          "frequencyPenalty": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInference_LLMs_0-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "huggingFaceInference_LLMs",
            "label": "HuggingFaceInference",
            "description": "Wrapper around HuggingFace large language models",
            "type": "HuggingFaceInference | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 578,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -421.71478613784376,
        "y": -983.5796043158841
      }
    },
    {
      "id": "customTool_1",
      "position": {
        "x": -53.77567759699744,
        "y": 11.31286470948146
      },
      "type": "customNode",
      "data": {
        "id": "customTool_1",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_1-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_1-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "75292a7d-1f56-4755-b387-1fdd7b40e228",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 374,
      "selected": false,
      "positionAbsolute": {
        "x": -53.77567759699744,
        "y": 11.31286470948146
      },
      "dragging": false
    },
    {
      "id": "inMemoryCache_0",
      "position": {
        "x": -783.1848651509565,
        "y": -1022.0442553293265
      },
      "type": "customNode",
      "data": {
        "id": "inMemoryCache_0",
        "label": "InMemory Cache",
        "version": 1,
        "name": "inMemoryCache",
        "type": "InMemoryCache",
        "baseClasses": [
          "InMemoryCache",
          "BaseCache"
        ],
        "category": "Cache",
        "description": "Cache LLM response in memory, will be cleared once app restarted",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
            "name": "inMemoryCache",
            "label": "InMemoryCache",
            "description": "Cache LLM response in memory, will be cleared once app restarted",
            "type": "InMemoryCache | BaseCache"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 144,
      "selected": false,
      "positionAbsolute": {
        "x": -783.1848651509565,
        "y": -1022.0442553293265
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "requestsGet_0",
      "sourceHandle": "requestsGet_0-output-requestsGet-RequestsGet|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "requestsGet_0-requestsGet_0-output-requestsGet-RequestsGet|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "chainTool_0",
      "sourceHandle": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "chainTool_0-chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "retrievalQAChain_0",
      "sourceHandle": "retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|Runnable",
      "target": "chainTool_0",
      "targetHandle": "chainTool_0-input-baseChain-BaseChain",
      "type": "buttonedge",
      "id": "retrievalQAChain_0-retrievalQAChain_0-output-retrievalQAChain-RetrievalQAChain|BaseChain|Runnable-chainTool_0-chainTool_0-input-baseChain-BaseChain"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "retrievalQAChain_0",
      "targetHandle": "retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-retrievalQAChain_0-retrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "googleGenerativeAiEmbeddings_0",
      "sourceHandle": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "googleGenerativeAiEmbeddings_0-googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "csvFile_0",
      "sourceHandle": "csvFile_0-output-document-Document|json",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "csvFile_0-csvFile_0-output-document-Document|json-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "characterTextSplitter_0",
      "sourceHandle": "characterTextSplitter_0-output-characterTextSplitter-CharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "csvFile_0",
      "targetHandle": "csvFile_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "characterTextSplitter_0-characterTextSplitter_0-output-characterTextSplitter-CharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-csvFile_0-csvFile_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "huggingFaceInference_LLMs_0",
      "sourceHandle": "huggingFaceInference_LLMs_0-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable",
      "target": "retrievalQAChain_0",
      "targetHandle": "retrievalQAChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "huggingFaceInference_LLMs_0-huggingFaceInference_LLMs_0-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable-retrievalQAChain_0-retrievalQAChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "customTool_1",
      "sourceHandle": "customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_1-customTool_1-output-customTool-CustomTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool"
    },
    {
      "source": "inMemoryCache_0",
      "sourceHandle": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
      "target": "huggingFaceInference_LLMs_0",
      "targetHandle": "huggingFaceInference_LLMs_0-input-cache-BaseCache",
      "type": "buttonedge",
      "id": "inMemoryCache_0-inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache-huggingFaceInference_LLMs_0-huggingFaceInference_LLMs_0-input-cache-BaseCache"
    }
  ]
}